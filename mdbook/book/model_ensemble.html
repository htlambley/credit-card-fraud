<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Ensembles - Detecting Credit Card Fraud with Machine Learning</title>
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="intro.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="intro_background.html"><strong aria-hidden="true">1.1.</strong> Background</a></li><li class="chapter-item expanded "><a href="intro_dataset.html"><strong aria-hidden="true">1.2.</strong> Dataset</a></li></ol></li><li class="chapter-item expanded "><a href="binary_classification.html"><strong aria-hidden="true">2.</strong> Binary Classification</a></li><li class="chapter-item expanded "><a href="eda.html"><strong aria-hidden="true">3.</strong> Exploratory Data Analysis</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="eda_classes.html"><strong aria-hidden="true">3.1.</strong> Imbalanced Classes</a></li><li class="chapter-item expanded "><a href="eda_seasonality.html"><strong aria-hidden="true">3.2.</strong> Seasonality</a></li></ol></li><li class="chapter-item expanded "><a href="model_baseline.html"><strong aria-hidden="true">4.</strong> Baseline Model</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">5.</strong> Refining the Model</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="model_scaling.html"><strong aria-hidden="true">5.1.</strong> Scaling</a></li><li class="chapter-item expanded "><a href="model_feature_selection.html"><strong aria-hidden="true">5.2.</strong> Feature Selection</a></li><li class="chapter-item expanded "><a href="model_feature_engineering.html"><strong aria-hidden="true">5.3.</strong> Feature Engineering</a></li><li class="chapter-item expanded "><a href="model_ensemble.html" class="active"><strong aria-hidden="true">5.4.</strong> Ensembles</a></li></ol></li><li class="chapter-item expanded "><a href="frontiers.html"><strong aria-hidden="true">6.</strong> Frontiers of Machine Learning</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Detecting Credit Card Fraud with Machine Learning</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#ensembles" id="ensembles">Ensembles</a></h1>
<p>In the previous sections we've developed several models which all perform reasonably well. </p>
<pre><code class="language-python">import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.metrics import average_precision_score, precision_recall_curve
from os import path
from util import load_data, get_confidence, BOOK_PATH

linear_pipeline = Pipeline([
    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),
    ('scaler', StandardScaler()),
    ('clf', LinearRegression())
])

nn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf',  MLPClassifier(hidden_layer_sizes=(10,), alpha=0.001, random_state=2))
])

knn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', KNeighborsClassifier())
])

svm_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', SVC())
])

classifiers = [
    ('Linear Regression', linear_pipeline),
    ('Neural Network', nn_pipeline),
    ('KNN', knn_pipeline),
    ('SVM', svm_pipeline),
    ('Random Forest', RandomForestClassifier(n_jobs=-1, random_state=0))
]

X, y = load_data()

k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)
print('       Average precision score       ')
print('-------------------------------------')
print('Fold   Classifier               Score')
for i, (train_index, test_index) in enumerate(k_fold.split(X, y)):
    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]
    y_train, y_test = y[train_index], y[test_index]
    plt.figure()
    for name, classifier in classifiers:
        classifier.fit(X_train, y_train)
        y_score = get_confidence(classifier, X_test)
        print(f'{i + 1:&lt;6} {name:&lt;24} {average_precision_score(y_test, y_score):.3f}')
        curve = precision_recall_curve(y_test, y_score)
        plt.plot(curve[0], curve[1], label=name)
    plt.legend(loc='lower left')
    plt.title(f'Fold {i + 1} precision—recall curve for classification models')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.savefig(path.join(BOOK_PATH, 'images', f'final_fold{i + 1}.png'))
    print()

</code></pre>
<p><img src="images/final_fold1.png" alt="Results on fold 1 for refined classifiers" />
<img src="images/final_fold2.png" alt="Results on fold 2 for refined classifiers" />
<img src="images/final_fold3.png" alt="Results on fold 3 for refined classifiers" />
<img src="images/final_fold4.png" alt="Results on fold 4 for refined classifiers" />
<img src="images/final_fold5.png" alt="Results on fold 5 for refined classifiers" /></p>
<p>All of these models are broadly comparable. The random forest still proves hard to beat, but generally the models all perform broadly 
equivalently.</p>
<p>We might now consider what's going wrong with these classifiers: which transactions cause problems? If they all fail on the same transactions, this might just mean they're difficult to learn. If not, we might be able to combine the learners into one which is more powerful than any individual classifier.</p>
<h2><a class="header" href="#errors" id="errors">Errors</a></h2>
<p>We investigate the idea we just mentioned: do the classifiers tend to predict the label incorrectly on the same transactions?</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.metrics import precision_recall_curve, accuracy_score
from util import load_data, get_confidence
import itertools

# We create popelines from the various successful models we've developed.
linear_pipeline = Pipeline([
    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),
    ('scaler', StandardScaler()),
    ('clf', LinearRegression())
])

nn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf',  MLPClassifier(hidden_layer_sizes=(10,), alpha=0.001, random_state=2))
])

knn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', KNeighborsClassifier())
])

svm_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', SVC())
])

classifiers = [
    ('Linear Regression', linear_pipeline),
    ('Neural Network', nn_pipeline),
    ('KNN', knn_pipeline),
    ('SVM', svm_pipeline),
    ('Random Forest', RandomForestClassifier(n_jobs=-1, random_state=0))
]


def find_best_threshold(y_true, y_score):
    curve = precision_recall_curve(y_true, y_score)
    thresholds = curve[2]
    accuracy = []
    for threshold in thresholds:
        accuracy.append(accuracy_score(y_true, y_score &gt; threshold))
    return thresholds[np.argmax(accuracy)]

X, y = load_data()

# We will collect the indices of the misclassified transactions (in fold 1) in
# misclassified. We then plot a histogram which shows us how many times each transaction
# was misclassified. We test using 5 classification pipelines, so if a transaction has
# been misclassified by all 5, it will show as a bar of 5.
misclassified = []
k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)
for i, (train_index, test_index) in enumerate(k_fold.split(X, y)):
    # Only evaluate the first fold for brevity.
    if i &gt; 0:
        break
    
    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]
    y_train, y_test = y[train_index], y[test_index]
    for name, clf in classifiers:
        clf.fit(X_train, y_train)
        y_score = get_confidence(clf, X_test)
        # We want to test each classifier on its most accurate threshold.
        threshold = find_best_threshold(y_test, y_score)
        # Creates a numpy array that is 1 if the corresponding transaction
        # was correctly classified by clf.
        classified_correctly = (y_score &gt; threshold) == y_test

        # Find the indices of the misclassifications and append to the collection
        # misclassified.
        misclassifications = list(np.where(classified_correctly == 0)[0])
        misclassified.append(misclassifications)
        
    # misclassified contains 5 lists: one from each classifier. We flatten this into a
    # 1 dimensional list.
    misclassified_transactions = list(itertools.chain.from_iterable(misclassified))
    # Plot a histogram of the data to show the number of misclassifications.
    plt.hist(misclassified_transactions, bins=len(misclassified_transactions))
    plt.title('Number of times transaction misclassified by index')
    plt.xlabel('Index')
    plt.ylabel('Number of times misclassified')
    plt.ylim([0, 5])
    plt.show()

</code></pre>
<p><img src="images/ensemble_misclassifications.png" alt="Misclassification histogram" />
We can see that using the predictions of multiple classifiers, quite a few of the misclassifications can be avoided. Further investigation indeed shows that while some transactions are classified wrong by nearly all the models (which we might suspect are &quot;hard&quot; to classify), others are modelled better by some learners than others.</p>
<h2><a class="header" href="#hard-voting" id="hard-voting">Hard Voting</a></h2>
<p>One way of combining the learners is to use scikit-learn's <code>VotingClassifier</code>. In effect, we construct multiple independent models, get a prediction from each, and choose the most common label. If there's a tie, we choose the majority class. This method is known as <em>hard voting</em>, and only requires classifiers that assign labels in \(\{0, 1\}\). The <code>VotingClassifier</code> also supports an alternative method known as <em>soft voting</em>, but this works best for classifiers which output predictions in \([0, 1]\) calibrated to probability estimates.</p>
<pre><code class="language-python">from sklearn.linear_model import RidgeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.metrics import precision_recall_fscore_support
from util import load_data

# To simplify usage in the VotingClassifier, we will use a RidgeClassifier instead of
# a LinearRegression model. This should behave very similarly with the regularisation 
# term so small.
linear_pipeline = Pipeline([
    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),
    ('scaler', StandardScaler()),
    ('clf', RidgeClassifier(alpha=0.00001))
])

nn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf',  MLPClassifier(hidden_layer_sizes=(10,), alpha=0.001, random_state=0))
])

knn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', KNeighborsClassifier())
])

svm_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', SVC())
])

classifiers = [
    ('Linear Model', linear_pipeline),
    ('Neural Network', nn_pipeline),
    ('KNN', knn_pipeline),
    ('SVM', svm_pipeline),
    ('Random Forest', RandomForestClassifier(n_jobs=-1, random_state=0))
]

voting_clf = VotingClassifier(classifiers)
X, y = load_data()

k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)
for i, (train_index, test_index) in enumerate(k_fold.split(X, y)):
    # For brevity, we will just test the model on the first fold.
    if i &gt; 0:
        break
    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]
    y_train, y_test = y[train_index], y[test_index]
    voting_clf.fit(X_train, y_train)
    y_pred = voting_clf.predict(X_test)
    precision, recall, f_score, _ = precision_recall_fscore_support(y_test, y_pred)
    # Precision, recall and f_score are calculated with respect to both classes,
    # but we are only interested in the fraud class (1).
    print(f'Precision: {precision[1]:.3f}')
    print(f'Recall: {recall[1]:.3f}')
    print(f'f-score: {f_score[1]:.3f}')

</code></pre>
<h3><a class="header" href="#output" id="output">Output</a></h3>
<pre><code>Precision: 0.948
Recall: 0.737
f-score: 0.830
</code></pre>
<p>The voting classifer has a precision of 0.95 and a recall of 0.74. This means that almost all of the fraudulent cases flagged by the classifier are correct, at a cost of missing a larger fraction of the true fraud. Depending on business parameters, this might be preferable to a very high recall; we can easily obtain a recall in excess of 0.95 with the individual models, but precision is much lower. Depending on whether it is worse to miss fraud or falsely flag genuine transactions, we can choose the appropriate model.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="model_feature_engineering.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="frontiers.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="model_feature_engineering.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="frontiers.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        
        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            var socket = new WebSocket("ws://localhost:3000/__livereload");
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>
        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>
